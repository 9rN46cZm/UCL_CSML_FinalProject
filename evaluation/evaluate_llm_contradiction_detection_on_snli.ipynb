{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import json\n",
    "from transformers import PerceiverTokenizer, PerceiverModel, PerceiverConfig, PerceiverPreTrainedModel, PerceiverForSequenceClassification, TrainingArguments, Trainer, \\\n",
    "    DataCollatorWithPadding\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "ROOT_PATH = \"..\"\n",
    "\n",
    "id2label = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "snli_dataset = load_dataset(\"stanfordnlp/snli\")\n",
    "\n",
    "for mode in ['train', 'validation', 'test']:\n",
    "    snli_dataset[mode] = snli_dataset[mode].filter(lambda e: e['label'] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9824 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724075497.002477   29801 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "100%|██████████| 9824/9824 [1:20:17<00:00,  2.04it/s, neutral 7094 9808 0.7232871125611745 16]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7094 9808 0.7232871125611745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "project_id = None\n",
    "\n",
    "vertexai.init(project=project_id, location=\"europe-west2\")\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-flash-001\")\n",
    "\n",
    "accurate_cnt = 0\n",
    "total_cnt = 0\n",
    "exception_cnt = 0\n",
    "responses = []\n",
    "labels = []\n",
    "for test_e in (pbar:=tqdm(snli_dataset['test'], total=len(snli_dataset['test']))):\n",
    "    premise = test_e['premise']\n",
    "    hypothesis = test_e['hypothesis']\n",
    "    label = test_e['label']\n",
    "    while True:\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "f\"\"\"You will be given a premise and a hypothesis. Output the relationship between the premise and the hypothesis. Your answer should be either 'entailment', 'neutral', or 'contradiction'. Do not include anything else in your answer, including special symbols.\n",
    "Premise: {premise}\n",
    "Hypothesis: {hypothesis}\n",
    "\"\"\")\n",
    "            break\n",
    "        except:\n",
    "            pbar.set_postfix_str(f\"sleeping {accurate_cnt} {total_cnt} {0 if not total_cnt else accurate_cnt / total_cnt } {exception_cnt}\")\n",
    "            time.sleep(70)\n",
    "    try:\n",
    "        response = response.text.strip()\n",
    "        response_id = -1 if response not in label2id else label2id[response]\n",
    "        if response_id == label:\n",
    "            accurate_cnt += 1\n",
    "        total_cnt += 1\n",
    "    except:\n",
    "        response = \"exception\"\n",
    "        exception_cnt += 1\n",
    "    responses.append(response)\n",
    "    labels.append(label)\n",
    "    pbar.set_postfix_str(f\"{response} {accurate_cnt} {total_cnt} {0 if not total_cnt else accurate_cnt / total_cnt } {exception_cnt}\")\n",
    "print(accurate_cnt, total_cnt, accurate_cnt / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3101  258    7]\n",
      " [ 374 2817   18]\n",
      " [  20 2037 1176]]\n"
     ]
    }
   ],
   "source": [
    "### Get confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels_ = []\n",
    "preds_ = []\n",
    "for i in range(len(labels)):\n",
    "    if responses[i] in label2id:\n",
    "        labels_.append(labels[i])\n",
    "        preds_.append(label2id[responses[i]])\n",
    "\n",
    "conf_mat = confusion_matrix(labels_, preds_)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the data\n",
    "import pickle\n",
    "\n",
    "save_dir_path = \"../ignored_dir/results/llm_contradiction_detection_on_snli\"\n",
    "if not os.path.exists(save_dir_path):\n",
    "    os.mkdir(save_dir_path)\n",
    "readme_path = os.path.join(save_dir_path, \"README.txt\")\n",
    "with open(readme_path, \"w\") as f:\n",
    "    f.write('{0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}')\n",
    "conf_mat_path = os.path.join(save_dir_path, \"conf_mat.pkl\")\n",
    "conf_mat_filehandler = open(conf_mat_path, 'wb') \n",
    "pickle.dump(conf_mat, conf_mat_filehandler)\n",
    "conf_mat_filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3101  258    7]\n",
      " [ 374 2817   18]\n",
      " [  20 2037 1176]]\n"
     ]
    }
   ],
   "source": [
    "### Test load\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "save_dir_path = \"../ignored_dir/results/llm_contradiction_detection_on_snli\"\n",
    "conf_mat_path = os.path.join(save_dir_path, \"conf_mat.pkl\")\n",
    "\n",
    "with open(conf_mat_path, 'rb') as f:\n",
    "    conf_mat_loaded = pickle.load(f)\n",
    "print(conf_mat_loaded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7232871125611745\n"
     ]
    }
   ],
   "source": [
    "acc = sum([conf_mat_loaded[i][i] for i in range(3)]) / sum(sum(conf_mat_loaded))\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['entailment', 'neutral', 'contradiction']\n",
      "\\begin{center}\n",
      "\\begin{tabular}{ |c|c|c|c|c| } \n",
      "\\hline\n",
      "& \\multicolumn{4}{|c|}{pred} \\\\\n",
      "\\hline\n",
      "\\multirow{4}{2em}{true} &  & entailment & neutral & contradiction \\\\\n",
      "\\cline{2-5}\n",
      "& entailment & 3101 & 258 & 7\\\\\n",
      "\\cline{2-5}\n",
      "& neutral & 374 & 2817 & 18\\\\\n",
      "\\cline{2-5}\n",
      "& contradiction & 20 & 2037 & 1176\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "### Make table\n",
    "conf_mat = conf_mat_loaded\n",
    "\n",
    "id2label = {0: \"entailment\", 1: \"neutral\", 2: \"contradiction\"}\n",
    "labels = [id2label[i] for i in range(3)]\n",
    "print(labels)\n",
    "\n",
    "latex_table = \"\"\"\\\\begin{center}\n",
    "\\\\begin{tabular}{ |c|c|c|c|c| } \n",
    "\\hline\n",
    "& \\multicolumn{4}{|c|}{pred} \\\\\\\\\n",
    "\\hline\n",
    "\\multirow{4}{2em}{true} &  & \"\"\" + f\"{labels[0]} & {labels[1]} & {labels[2]} \\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[0]} & {conf_mat[0][0]} & {conf_mat[0][1]} & {conf_mat[0][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[1]} & {conf_mat[1][0]} & {conf_mat[1][1]} & {conf_mat[1][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[2]} & {conf_mat[2][0]} & {conf_mat[2][1]} & {conf_mat[2][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{center}\"\"\"\n",
    "\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
