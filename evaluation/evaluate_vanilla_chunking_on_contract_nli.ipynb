{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on contract nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"..\"\n",
    "\n",
    "id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "def contract_nli_iterator(data):\n",
    "    documents, labels = data['documents'], data['labels']\n",
    "    for document in documents:\n",
    "        id = document['id']\n",
    "        file_name = document['file_name']\n",
    "        text = document['text']\n",
    "        spans = document['spans']\n",
    "        annotation_sets = document['annotation_sets']\n",
    "        document_type = document['document_type']\n",
    "        url = document['url']\n",
    "        for annotation_id, annotation_content in annotation_sets[0]['annotations'].items():\n",
    "            hypothesis = labels[annotation_id]['hypothesis']\n",
    "            choice = annotation_content['choice']\n",
    "            yield {\n",
    "                \"id\": id,\n",
    "                \"file_name\": file_name,\n",
    "                \"text\": text,\n",
    "                \"spans\": spans,\n",
    "                \"document_type\": document_type,\n",
    "                \"url\": url,\n",
    "                \"hypothesis\": hypothesis,\n",
    "                \"labels\": label2id[choice],\n",
    "            }            \n",
    "base_filepath = os.path.join(ROOT_PATH, \"ignored_dir/data/contract-nli\")\n",
    "train_filepath = os.path.join(base_filepath, \"train.json\")\n",
    "validation_filepath = os.path.join(base_filepath, \"dev.json\")\n",
    "test_filepath = os.path.join(base_filepath, \"test.json\")\n",
    "with open(train_filepath) as f:\n",
    "    train_data = json.load(f)\n",
    "with open(validation_filepath) as f:\n",
    "    validation_data = json.load(f)\n",
    "with open(test_filepath) as f:\n",
    "    test_data = json.load(f)\n",
    "data = {\n",
    "    \"train\": Dataset.from_generator(lambda: contract_nli_iterator(train_data)),\n",
    "    \"validation\": Dataset.from_generator(lambda: contract_nli_iterator(validation_data)),\n",
    "    \"test\": Dataset.from_generator(lambda: contract_nli_iterator(test_data)),\n",
    "}\n",
    "contract_nli_dataset = DatasetDict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate vanilla chunking on contract nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_nli_dataset_validation = contract_nli_dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'file_name', 'text', 'spans', 'document_type', 'url', 'hypothesis', 'labels'])\n",
      "id 3\n",
      "file-name 09-24-2019-04-25-05-3914910473.pdf\n",
      "text omitted\n",
      "spans [[0, 14], [15, 67], [68, 127], [128, 282], [283, 362], [362, 455], [455, 492], [493, 559], [559, 653], [653, 690], [691, 793], [794, 801], [802, 1278], [1278, 1358], [1359, 1383], [1384, 1416], [1417, 1490], [1491, 1907], [1908, 2178], [2178, 2475], [2475, 2638], [2639, 2795], [2796, 2927], [2928, 3074], [3075, 3088], [3089, 3202], [3203, 3344], [3345, 3544], [3545, 3725], [3726, 3932], [3933, 3998], [3999, 4125], [4126, 4171], [4172, 4214], [4215, 4311], [4312, 4457], [4458, 4569], [4570, 4738], [4739, 4867], [4868, 4965], [4966, 5059], [5060, 5092], [5093, 5298], [5298, 5743], [5743, 5857], [5858, 5895], [5896, 6027], [6027, 6271], [6271, 6610], [6610, 6749], [6750, 6770], [6771, 6949], [6949, 7020], [7020, 7162], [7163, 7179], [7180, 7351], [7351, 7556], [7557, 7566], [7567, 7939], [7940, 7954], [7955, 8100], [8100, 8222], [8223, 8235], [8236, 8333], [8333, 8521], [8521, 8851], [8851, 9031], [9032, 9061], [9062, 9341], [9342, 9377], [9378, 9531], [9531, 9698], [9699, 9724], [9725, 9914], [9915, 9932], [9933, 10018], [10019, 10037], [10038, 10289], [10290, 10297], [10298, 10307], [10308, 10328], [10329, 10339], [10340, 10347], [10348, 10357], [10358, 10378], [10379, 10389], [10390, 10529], [10530, 10608], [10609, 10620], [10621, 10693], [10693, 10990], [10991, 11049], [11050, 11091], [11092, 11107], [11108, 11121], [11122, 11131], [11132, 11141]]\n",
      "document_type search-pdf\n",
      "url https://www.oisair.net/uploads/pages/09-24-2019-04-25-05-3914910473.pdf\n",
      "hypothesis Receiving Party shall not reverse engineer any objects which embody Disclosing Party's Confidential Information.\n",
      "labels 0\n"
     ]
    }
   ],
   "source": [
    "for e in contract_nli_dataset_validation:\n",
    "    print(e.keys())\n",
    "    print('id', e['id'])\n",
    "    print('file-name', e['file_name'])\n",
    "    print('text', 'omitted') # e['text'])\n",
    "    print('spans', e['spans'])\n",
    "    print('document_type', e['document_type'])\n",
    "    print('url', e['url'])\n",
    "    print('hypothesis', e['hypothesis'])\n",
    "    print('labels', e['labels'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fe2087de794635855f315e4bb30210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2270 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmp = None\n",
    "for e in contract_nli_dataset_validation:\n",
    "    tmp = e\n",
    "    break\n",
    "\n",
    "facebook_bart_large_mnli_autotokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
    "documents = [Document(text=e['text'])]\n",
    "parser = SentenceSplitter(chunk_size=200, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\n",
    "nodes = parser.get_nodes_from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OISAIR PROJECT\n",
      "TWO-WAY CONFIDENTIALITY AND NON-DISCLOSURE AGREEMENT\n",
      "(TO BE SIGNED ELECTRONICALLY THROUGH THE INNOVAIR PLATFORM)\n",
      "This Confidentiality and Non-Disclosure Agreement (hereinafter referred to as the “Agreement”) dated ………………………. (“Effective Date”) is made by and between:\n",
      "1) <Research institution name> with registered offices located in ……………………………, Tax registration No ………, represented by ………………………………….., in the legal capacity as …………………….. Hereinafter referred to as “………………..”\n",
      "2) <Company name> with registered offices located in ………………………….. Tax registration No.\n"
     ]
    }
   ],
   "source": [
    "for e in nodes:\n",
    "    print(e.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device {device}\")\n",
    "facebook_bart_large_mnli_automodel_for_sequence_classification = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_4823/1092091341.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  tokens = torch.tensor(tokens)\n"
     ]
    }
   ],
   "source": [
    "# prop = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[law_node.text, contract_node.text] for law_node in law_nodes_chunk], return_tensors='pt', padding='longest', truncation='only_first')['input_ids']\n",
    "\n",
    "\n",
    "tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[nodes[0].text, \"haha\"]], return_tensors='pt', padding='longest', truncation='only_first')['input_ids']\n",
    "tokens = torch.tensor(tokens)\n",
    "ret = facebook_bart_large_mnli_automodel_for_sequence_classification(tokens.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0773,  0.5191, -1.5044]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(ret.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[1, 2], [-1, 2]], dtype=torch.float64)\n",
    "nn.Softmax(dim=1)(test)\n",
    "torch.mean(test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "bart_large_mnli_label2id = {v: k for k, v in bart_large_mnli_id2labal.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bart_label_to_contract_nli_label(id):\n",
    "    if id == 0: return 1\n",
    "    elif id == 1: return 2\n",
    "    elif id == 2: return 0\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparser = SentenceSplitter(chunk_size=300, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\\n#contract_nodes = parser.get_nodes_from_documents(contract_documents, show_progress=True)\\n\\nchunk_record = dict()\\nsoftmax_f = nn.Softmax(dim=1)\\naveraged_probs_record = torch.tensor([[0.0, 0.0, 0.0] for _ in range(len(contract_nli_dataset_validation))])\\naccuracy_record = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\\nwith torch.no_grad():\\n    for i, e in tqdm(enumerate(contract_nli_dataset_validation), total=len(contract_nli_dataset_validation)):\\n        premise = e['text']\\n        hypothesis = e['hypothesis']\\n        premise_chunks = chunk_record.get(e['file_name'], None)\\n        if premise_chunks is None:\\n            premise_chunks = parser.get_nodes_from_documents([Document(text=premise)])\\n            premise_chunks = [e.text for e in premise_chunks]\\n            chunk_record[e['file_name']] = premise_chunks\\n        e_tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[premise_chunk, hypothesis] for premise_chunk in premise_chunks], return_tensors='pt', padding='longest', truncation='only_first')\\n        e_tokens = e_tokens['input_ids'].detach().cpu()\\n        logits = facebook_bart_large_mnli_automodel_for_sequence_classification(e_tokens.to(device)).logits\\n        averaged_probs = torch.mean(softmax_f(logits), dim=0)\\n        averaged_probs_record[i] = averaged_probs\\n        ans = torch.argmax(averaged_probs)\\n        label = e['labels']\\n        accuracy_record[i] = 1 if label == bart_label_to_contract_nli_label(ans) else 0\\nprint(torch.mean(accuracy_record))\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "parser = SentenceSplitter(chunk_size=300, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\n",
    "#contract_nodes = parser.get_nodes_from_documents(contract_documents, show_progress=True)\n",
    "\n",
    "chunk_record = dict()\n",
    "softmax_f = nn.Softmax(dim=1)\n",
    "averaged_probs_record = torch.tensor([[0.0, 0.0, 0.0] for _ in range(len(contract_nli_dataset_validation))])\n",
    "accuracy_record = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\n",
    "with torch.no_grad():\n",
    "    for i, e in tqdm(enumerate(contract_nli_dataset_validation), total=len(contract_nli_dataset_validation)):\n",
    "        premise = e['text']\n",
    "        hypothesis = e['hypothesis']\n",
    "        premise_chunks = chunk_record.get(e['file_name'], None)\n",
    "        if premise_chunks is None:\n",
    "            premise_chunks = parser.get_nodes_from_documents([Document(text=premise)])\n",
    "            premise_chunks = [e.text for e in premise_chunks]\n",
    "            chunk_record[e['file_name']] = premise_chunks\n",
    "        e_tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[premise_chunk, hypothesis] for premise_chunk in premise_chunks], return_tensors='pt', padding='longest', truncation='only_first')\n",
    "        e_tokens = e_tokens['input_ids'].detach().cpu()\n",
    "        logits = facebook_bart_large_mnli_automodel_for_sequence_classification(e_tokens.to(device)).logits\n",
    "        averaged_probs = torch.mean(softmax_f(logits), dim=0)\n",
    "        averaged_probs_record[i] = averaged_probs\n",
    "        ans = torch.argmax(averaged_probs)\n",
    "        label = e['labels']\n",
    "        accuracy_record[i] = 1 if label == bart_label_to_contract_nli_label(ans) else 0\n",
    "print(torch.mean(accuracy_record))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\\n# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\\n\\ntmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\\ncontradiction_cnt = 0\\nlabel_sum = dict()\\nfor i, e in enumerate(contract_nli_dataset_validation):\\n    averaged_probs = averaged_probs_record[i]\\n    ans = 1 if averaged_probs[0] > 0.9 else 0\\n    # ans = torch.argmax(averaged_probs)\\n    label = e[\\'labels\\']\\n    label_sum[id2label[label]] = label_sum.get(id2label[label], 0) + 1\\n    # ans = bart_label_to_contract_nli_label(ans)\\n    ans = 1 if ans == 1 else 0\\n    label = 1 if label == 1 else 0\\n    tmp[i] = 1 if ans == label else 0\\n    if label == 1:\\n        contradiction_cnt += 1\\nprint(torch.mean(tmp))\\nprint(contradiction_cnt, len(contract_nli_dataset_validation))\\nprint(label_sum)\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results analysis: Turn into two categories.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\n",
    "contradiction_cnt = 0\n",
    "label_sum = dict()\n",
    "for i, e in enumerate(contract_nli_dataset_validation):\n",
    "    averaged_probs = averaged_probs_record[i]\n",
    "    ans = 1 if averaged_probs[0] > 0.9 else 0\n",
    "    # ans = torch.argmax(averaged_probs)\n",
    "    label = e['labels']\n",
    "    label_sum[id2label[label]] = label_sum.get(id2label[label], 0) + 1\n",
    "    # ans = bart_label_to_contract_nli_label(ans)\n",
    "    ans = 1 if ans == 1 else 0\n",
    "    label = 1 if label == 1 else 0\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "    if label == 1:\n",
    "        contradiction_cnt += 1\n",
    "print(torch.mean(tmp))\n",
    "print(contradiction_cnt, len(contract_nli_dataset_validation))\n",
    "print(label_sum)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\\n# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\\n\\ntmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\\ncontradiction_cnt = 0\\nlabel_sum = dict()\\nfor i, e in enumerate(contract_nli_dataset_validation):\\n    averaged_probs = averaged_probs_record[i]\\n    ans = 1 if averaged_probs[0] > 0.9 else (0 if averaged_probs[1] > 0.9 else 2)\\n    # ans = torch.argmax(averaged_probs)\\n    label = e[\\'labels\\']\\n    tmp[i] = 1 if ans == label else 0\\nprint(torch.mean(tmp))\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results analysis: Set threshold for neutral as well.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_validation))])\n",
    "contradiction_cnt = 0\n",
    "label_sum = dict()\n",
    "for i, e in enumerate(contract_nli_dataset_validation):\n",
    "    averaged_probs = averaged_probs_record[i]\n",
    "    ans = 1 if averaged_probs[0] > 0.9 else (0 if averaged_probs[1] > 0.9 else 2)\n",
    "    # ans = torch.argmax(averaged_probs)\n",
    "    label = e['labels']\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "print(torch.mean(tmp))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTry on test set. Test set should be used for testing?\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Try on test set. Test set should be used for testing?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_nli_dataset_test = contract_nli_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2091/2091 [11:06<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Try all data to see if results persist. \n",
    "\"\"\"\n",
    "parser = SentenceSplitter(chunk_size=300, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\n",
    "#contract_nodes = parser.get_nodes_from_documents(contract_documents, show_progress=True)\n",
    "\n",
    "softmax_f = nn.Softmax(dim=1)\n",
    "chunk_record_test = dict()\n",
    "averaged_probs_record_test = torch.tensor([[0.0, 0.0, 0.0] for _ in range(len(contract_nli_dataset_test))])\n",
    "accuracy_record_test = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_test))])\n",
    "with torch.no_grad():\n",
    "    for i, e in tqdm(enumerate(contract_nli_dataset_test), total=len(contract_nli_dataset_test)):\n",
    "        premise = e['text']\n",
    "        hypothesis = e['hypothesis']\n",
    "        premise_chunks = chunk_record_test.get(e['file_name'], None)\n",
    "        if premise_chunks is None:\n",
    "            premise_chunks = parser.get_nodes_from_documents([Document(text=premise)])\n",
    "            premise_chunks = [e.text for e in premise_chunks]\n",
    "            chunk_record_test[e['file_name']] = premise_chunks\n",
    "        e_tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[premise_chunk, hypothesis] for premise_chunk in premise_chunks], return_tensors='pt', padding='longest', truncation='only_first')\n",
    "        e_tokens = e_tokens['input_ids'].detach().cpu()\n",
    "        logits = facebook_bart_large_mnli_automodel_for_sequence_classification(e_tokens.to(device)).logits\n",
    "        averaged_probs = torch.mean(softmax_f(logits), dim=0)\n",
    "        averaged_probs_record_test[i] = averaged_probs\n",
    "        ans = torch.argmax(averaged_probs)\n",
    "        label = e['labels']\n",
    "        accuracy_record_test[i] = 1 if label == bart_label_to_contract_nli_label(ans) else 0\n",
    "print(torch.mean(accuracy_record_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181 341 446]\n",
      " [ 14 117  89]\n",
      " [ 80 467 356]]\n"
     ]
    }
   ],
   "source": [
    "### Get confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "\n",
    "for i, e in enumerate(contract_nli_dataset_test):\n",
    "    averaged_probs = averaged_probs_record_test[i]\n",
    "    ans = torch.argmax(averaged_probs)\n",
    "    ans = bart_label_to_contract_nli_label(ans)\n",
    "    preds.append(ans)\n",
    "    label = e['labels']\n",
    "    labels.append(label)\n",
    "\n",
    "conf_mat = confusion_matrix(labels, preds)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the data\n",
    "import pickle\n",
    "\n",
    "save_dir_path = \"../ignored_dir/results/vanilla_chunking_on_contract_nli\"\n",
    "if not os.path.exists(save_dir_path):\n",
    "    os.mkdir(save_dir_path)\n",
    "readme_path = os.path.join(save_dir_path, \"README.txt\")\n",
    "with open(readme_path, \"w\") as f:\n",
    "    f.write('{0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}')\n",
    "conf_mat_path = os.path.join(save_dir_path, \"conf_mat.pkl\")\n",
    "conf_mat_filehandler = open(conf_mat_path, 'wb') \n",
    "pickle.dump(conf_mat, conf_mat_filehandler)\n",
    "conf_mat_filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181 341 446]\n",
      " [ 14 117  89]\n",
      " [ 80 467 356]]\n"
     ]
    }
   ],
   "source": [
    "### Test \n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "save_dir_path = \"../ignored_dir/results/vanilla_chunking_on_contract_nli\"\n",
    "conf_mat_path = os.path.join(save_dir_path, \"conf_mat.pkl\")\n",
    "\n",
    "with open(conf_mat_path, 'rb') as f:\n",
    "    conf_mat_loaded = pickle.load(f)\n",
    "print(conf_mat_loaded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make table\n",
    "conf_mat = conf_mat_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3127690100430416\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum([conf_mat[i][i] for i in range(3)]) / sum(sum(conf_mat))\n",
    "print(f\"accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entailment', 'Contradiction', 'NotMentioned']\n"
     ]
    }
   ],
   "source": [
    "id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "labels = [id2label[i] for i in range(3)]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = \"\"\"\\\\begin{center}\n",
    "\\\\begin{tabular}{ |c|c|c|c|c| } \n",
    "\\hline\n",
    "& \\multicolumn{4}{|c|}{pred} \\\\\\\\\n",
    "\\hline\n",
    "\\multirow{4}{2em}{true} &  & \"\"\" + f\"{labels[0]} & {labels[1]} & {labels[2]} \\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[0]} & {conf_mat[0][0]} & {conf_mat[0][1]} & {conf_mat[0][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[1]} & {conf_mat[1][0]} & {conf_mat[1][1]} & {conf_mat[1][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\cline{2-5}\n",
    "& \"\"\" + f\"{labels[2]} & {conf_mat[2][0]} & {conf_mat[2][1]} & {conf_mat[2][2]}\\\\\\\\\\n\" \\\n",
    "+ \"\"\"\\hline\n",
    "\\end{tabular}\n",
    "\\end{center}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{ |c|c|c|c|c| } \n",
      "\\hline\n",
      "& \\multicolumn{4}{|c|}{pred} \\\\\n",
      "\\hline\n",
      "\\multirow{4}{2em}{true} &  & Entailment & Contradiction & NotMentioned \\\\\n",
      "\\cline{2-5}\n",
      "& Entailment & 181 & 341 & 446\\\\\n",
      "\\cline{2-5}\n",
      "& Contradiction & 14 & 117 & 89\\\\\n",
      "\\cline{2-5}\n",
      "& NotMentioned & 80 & 467 & 356\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mResults analysis: Turn into two categories.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tmp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(contract_nli_dataset_test))])\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/__init__.py:84\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     ]\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/_chunking.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/validation.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/_array_api.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[1;32m     13\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/sklearn/utils/fixes.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_packaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_threadpool_controller\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/stats/__init__.py:610\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    609\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (check_random_state, _get_nan,\n\u001b[1;32m     42\u001b[0m                               _rename_parameter, _contains_nan,\n\u001b[1;32m     43\u001b[0m                               AxisError)\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/spatial/__init__.py:123\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ckdtree, kdtree, qhull\n\u001b[1;32m    121\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance, transform\n\u001b[1;32m    125\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/spatial/transform/__init__.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSpatial Transformations (:mod:`scipy.spatial.transform`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m========================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m   RotationSpline\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rotation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rotation, Slerp\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rotation_spline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RotationSpline\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
      "File \u001b[0;32m_rotation.pyx:7\u001b[0m, in \u001b[0;36minit scipy.spatial.transform._rotation\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/spatial/transform/_rotation_groups.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m golden \u001b[38;5;28;01mas\u001b[39;00m phi\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21micosahedral\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m      6\u001b[0m     g1 \u001b[38;5;241m=\u001b[39m tetrahedral(\u001b[38;5;28mcls\u001b[39m)\u001b[38;5;241m.\u001b[39mas_quat()\n",
      "File \u001b[0;32m~/scc_yan/virtual-env/lib/python3.10/site-packages/scipy/constants/__init__.py:329\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_codata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _obsolete_constants, physical_constants\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m codata, constants\n\u001b[1;32m    331\u001b[0m _constant_names_list \u001b[38;5;241m=\u001b[39m [(_k\u001b[38;5;241m.\u001b[39mlower(), _k, _v)\n\u001b[1;32m    332\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m _k, _v \u001b[38;5;129;01min\u001b[39;00m physical_constants\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    333\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m _k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _obsolete_constants]\n\u001b[1;32m    334\u001b[0m _constant_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(_x[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m66\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(_x[\u001b[38;5;241m1\u001b[39m])),\n\u001b[1;32m    335\u001b[0m                                                   _x[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m], _x[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    336\u001b[0m                              \u001b[38;5;28;01mfor\u001b[39;00m _x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(_constant_names_list)])\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results analysis: Turn into two categories.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_test))])\n",
    "contradiction_cnt = 0\n",
    "label_sum = dict()\n",
    "labels_test = []\n",
    "preds_test = []\n",
    "for i, e in enumerate(contract_nli_dataset_test):\n",
    "    averaged_probs = averaged_probs_record_test[i]\n",
    "    ans = 1 if averaged_probs[0] > 0.9 else 0\n",
    "    # ans = torch.argmax(averaged_probs)\n",
    "    label = e['labels']\n",
    "    label_sum[id2label[label]] = label_sum.get(id2label[label], 0) + 1\n",
    "    # ans = bart_label_to_contract_nli_label(ans)\n",
    "    ans = 1 if ans == 1 else 0\n",
    "    label = 1 if label == 1 else 0\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "    labels_test.append(label)\n",
    "    preds_test.append(ans)\n",
    "    if label == 1:\n",
    "        contradiction_cnt += 1\n",
    "conf_mat_test = confusion_matrix(labels_test, preds_test)\n",
    "print(\"two category result\")\n",
    "print(torch.mean(tmp))\n",
    "print(contradiction_cnt, len(contract_nli_dataset_test))\n",
    "print(label_sum)\n",
    "print(conf_mat_test)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Results analysis: Set threshold for neutral as well.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_test))])\n",
    "contradiction_cnt = 0\n",
    "label_sum = dict()\n",
    "labels_test = []\n",
    "preds_test = []\n",
    "for i, e in enumerate(contract_nli_dataset_test):\n",
    "    averaged_probs = averaged_probs_record_test[i]\n",
    "    ans = bart_label_to_contract_nli_label(ans)\n",
    "    label = e['labels']\n",
    "    labels_test.append(label)\n",
    "    preds_test.append(ans)\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "print(\"three catogory with thresholding result\")\n",
    "print(torch.mean(tmp))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contract_nli_dataset_all = datasets.concatenate_datasets([contract_nli_dataset['train'], contract_nli_dataset['validation'], contract_nli_dataset['test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparser = SentenceSplitter(chunk_size=300, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\\n#contract_nodes = parser.get_nodes_from_documents(contract_documents, show_progress=True)\\n\\nchunk_record_all = dict()\\nsoftmax_f_all = nn.Softmax(dim=1)\\naveraged_probs_record_all = torch.tensor([[0.0, 0.0, 0.0] for _ in range(len(contract_nli_dataset_all))])\\naccuracy_record_all = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\\nwith torch.no_grad():\\n    for i, e in tqdm(enumerate(contract_nli_dataset_all), total=len(contract_nli_dataset_all)):\\n        premise = e['text']\\n        hypothesis = e['hypothesis']\\n        premise_chunks = chunk_record_all.get(e['file_name'], None)\\n        if premise_chunks is None:\\n            premise_chunks = parser.get_nodes_from_documents([Document(text=premise)])\\n            premise_chunks = [e.text for e in premise_chunks]\\n            chunk_record_all[e['file_name']] = premise_chunks\\n        e_tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[premise_chunk, hypothesis] for premise_chunk in premise_chunks], return_tensors='pt', padding='longest', truncation='only_first')\\n        e_tokens = e_tokens['input_ids'].detach().cpu()\\n        logits = facebook_bart_large_mnli_automodel_for_sequence_classification(e_tokens.to(device)).logits\\n        averaged_probs = torch.mean(softmax_f(logits), dim=0)\\n        averaged_probs_record_all[i] = averaged_probs\\n        ans = torch.argmax(averaged_probs)\\n        label = e['labels']\\n        accuracy_record_all[i] = 1 if label == bart_label_to_contract_nli_label(ans) else 0\\nprint(torch.mean(accuracy_record_all))\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Try all data to see if results persist. \n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "parser = SentenceSplitter(chunk_size=300, chunk_overlap=50, tokenizer=lambda x: facebook_bart_large_mnli_autotokenizer(x)['input_ids'])\n",
    "#contract_nodes = parser.get_nodes_from_documents(contract_documents, show_progress=True)\n",
    "\n",
    "chunk_record_all = dict()\n",
    "softmax_f_all = nn.Softmax(dim=1)\n",
    "averaged_probs_record_all = torch.tensor([[0.0, 0.0, 0.0] for _ in range(len(contract_nli_dataset_all))])\n",
    "accuracy_record_all = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\n",
    "with torch.no_grad():\n",
    "    for i, e in tqdm(enumerate(contract_nli_dataset_all), total=len(contract_nli_dataset_all)):\n",
    "        premise = e['text']\n",
    "        hypothesis = e['hypothesis']\n",
    "        premise_chunks = chunk_record_all.get(e['file_name'], None)\n",
    "        if premise_chunks is None:\n",
    "            premise_chunks = parser.get_nodes_from_documents([Document(text=premise)])\n",
    "            premise_chunks = [e.text for e in premise_chunks]\n",
    "            chunk_record_all[e['file_name']] = premise_chunks\n",
    "        e_tokens = facebook_bart_large_mnli_autotokenizer.batch_encode_plus([[premise_chunk, hypothesis] for premise_chunk in premise_chunks], return_tensors='pt', padding='longest', truncation='only_first')\n",
    "        e_tokens = e_tokens['input_ids'].detach().cpu()\n",
    "        logits = facebook_bart_large_mnli_automodel_for_sequence_classification(e_tokens.to(device)).logits\n",
    "        averaged_probs = torch.mean(softmax_f(logits), dim=0)\n",
    "        averaged_probs_record_all[i] = averaged_probs\n",
    "        ans = torch.argmax(averaged_probs)\n",
    "        label = e['labels']\n",
    "        accuracy_record_all[i] = 1 if label == bart_label_to_contract_nli_label(ans) else 0\n",
    "print(torch.mean(accuracy_record_all))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\\n# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\\n\\ntmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\\ncontradiction_cnt = 0\\ncontradiction_correct_cnt = 0\\nlabel_sum = dict()\\nfor i, e in enumerate(contract_nli_dataset_all):\\n    averaged_probs = averaged_probs_record_all[i]\\n    ans = 1 if averaged_probs[0] > 0.6 else 0\\n    # ans = torch.argmax(averaged_probs)\\n    label = e[\\'labels\\']\\n    label_sum[id2label[label]] = label_sum.get(id2label[label], 0) + 1\\n    # ans = bart_label_to_contract_nli_label(ans)\\n    ans = 1 if ans == 1 else 0\\n    label = 1 if label == 1 else 0\\n    tmp[i] = 1 if ans == label else 0\\n    if label == 1:\\n        contradiction_cnt += 1\\n    if ans == label == 1:\\n        contradiction_correct_cnt += 1\\nprint(torch.mean(tmp))\\nprint(f\"contradiction correct cnt: {contradiction_correct_cnt}\")\\nprint(f\"contradiction cnt: {contradiction_cnt}\")\\nprint(f\"contradiction hit rate: {contradiction_correct_cnt / contradiction_cnt}\")\\nprint(label_sum)\\n\\n\"\"\"\\nResults analysis: Set threshold for neutral as well.\\n\"\"\"\\n\\n# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\\n# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\\n\\ntmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\\ncontradiction_cnt = 0\\nlabel_sum = dict()\\nfor i, e in enumerate(contract_nli_dataset_all):\\n    averaged_probs = averaged_probs_record_all[i]\\n    ans = 1 if averaged_probs[0] > 0.9 else (0 if averaged_probs[1] > 0.9 else 2)\\n    # ans = torch.argmax(averaged_probs)\\n    label = e[\\'labels\\']\\n    tmp[i] = 1 if ans == label else 0\\nprint(torch.mean(tmp))\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results analysis: Turn into two categories.\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\n",
    "contradiction_cnt = 0\n",
    "contradiction_correct_cnt = 0\n",
    "label_sum = dict()\n",
    "for i, e in enumerate(contract_nli_dataset_all):\n",
    "    averaged_probs = averaged_probs_record_all[i]\n",
    "    ans = 1 if averaged_probs[0] > 0.6 else 0\n",
    "    # ans = torch.argmax(averaged_probs)\n",
    "    label = e['labels']\n",
    "    label_sum[id2label[label]] = label_sum.get(id2label[label], 0) + 1\n",
    "    # ans = bart_label_to_contract_nli_label(ans)\n",
    "    ans = 1 if ans == 1 else 0\n",
    "    label = 1 if label == 1 else 0\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "    if label == 1:\n",
    "        contradiction_cnt += 1\n",
    "    if ans == label == 1:\n",
    "        contradiction_correct_cnt += 1\n",
    "print(torch.mean(tmp))\n",
    "print(f\"contradiction correct cnt: {contradiction_correct_cnt}\")\n",
    "print(f\"contradiction cnt: {contradiction_cnt}\")\n",
    "print(f\"contradiction hit rate: {contradiction_correct_cnt / contradiction_cnt}\")\n",
    "print(label_sum)\n",
    "\n",
    "\"\"\"\n",
    "Results analysis: Set threshold for neutral as well.\n",
    "\"\"\"\n",
    "\n",
    "# bart_large_mnli_id2labal = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}\n",
    "# id2label = {0: \"Entailment\", 1: \"Contradiction\", 2: \"NotMentioned\"}\n",
    "\n",
    "tmp = torch.tensor([0.0 for _ in range(len(contract_nli_dataset_all))])\n",
    "contradiction_cnt = 0\n",
    "label_sum = dict()\n",
    "for i, e in enumerate(contract_nli_dataset_all):\n",
    "    averaged_probs = averaged_probs_record_all[i]\n",
    "    ans = 1 if averaged_probs[0] > 0.9 else (0 if averaged_probs[1] > 0.9 else 2)\n",
    "    # ans = torch.argmax(averaged_probs)\n",
    "    label = e['labels']\n",
    "    tmp[i] = 1 if ans == label else 0\n",
    "print(torch.mean(tmp))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
